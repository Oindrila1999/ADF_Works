{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "ADFDemoOindrila"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/lkp_actvty_all_rec_pipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Lookup_folder_names",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlServerSource",
								"sqlReaderQuery": "select NAMES from OUTPUTFOLDERS",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "SqlDBDataset",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ForEach_foldernames",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Lookup_folder_names",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Lookup_folder_names').output.value",
								"type": "Expression"
							},
							"isSequential": false,
							"batchCount": 5,
							"activities": [
								{
									"name": "Copy_input_output",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "BinarySource",
											"storeSettings": {
												"type": "AzureBlobStorageReadSettings",
												"recursive": true
											},
											"formatSettings": {
												"type": "BinaryReadSettings"
											}
										},
										"sink": {
											"type": "BinarySink",
											"storeSettings": {
												"type": "AzureBlobStorageWriteSettings"
											}
										},
										"enableStaging": false
									},
									"inputs": [
										{
											"referenceName": "inputDataDataset",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "output_dataset_lkp",
											"type": "DatasetReference",
											"parameters": {
												"Foldername": {
													"value": "@item().NAMES",
													"type": "Expression"
												}
											}
										}
									]
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"variables": {
					"firstrow": {
						"type": "Array"
					}
				},
				"annotations": [],
				"lastPublishTime": "2025-03-31T07:38:52Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/read_json_outputof_one_to_anothere')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Get Metadata1",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "ds_inputfolder",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata1').output.childItems",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Set variable1",
									"type": "SetVariable",
									"dependsOn": [],
									"policy": {
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"variableName": "Filename",
										"value": {
											"value": "@item().name",
											"type": "Expression"
										}
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"variables": {
					"Filename": {
						"type": "String"
					}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/switch_activity_pipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Switch1",
						"type": "Switch",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"on": {
								"value": "@pipeline().parameters.folder",
								"type": "Expression"
							},
							"cases": [
								{
									"value": "output1",
									"activities": [
										{
											"name": "Copy data1",
											"type": "Copy",
											"dependsOn": [],
											"policy": {
												"timeout": "0.12:00:00",
												"retry": 0,
												"retryIntervalInSeconds": 30,
												"secureOutput": false,
												"secureInput": false
											},
											"userProperties": [],
											"typeProperties": {
												"source": {
													"type": "BinarySource",
													"storeSettings": {
														"type": "AzureBlobStorageReadSettings",
														"recursive": true
													},
													"formatSettings": {
														"type": "BinaryReadSettings"
													}
												},
												"sink": {
													"type": "BinarySink",
													"storeSettings": {
														"type": "AzureBlobStorageWriteSettings"
													}
												},
												"enableStaging": false
											},
											"inputs": [
												{
													"referenceName": "inputDataDataset",
													"type": "DatasetReference",
													"parameters": {}
												}
											],
											"outputs": [
												{
													"referenceName": "outdataset_switch",
													"type": "DatasetReference",
													"parameters": {
														"foldername": {
															"value": "@pipeline().parameters.folder",
															"type": "Expression"
														}
													}
												}
											]
										}
									]
								},
								{
									"value": "output2",
									"activities": [
										{
											"name": "Copy data2",
											"type": "Copy",
											"dependsOn": [],
											"policy": {
												"timeout": "0.12:00:00",
												"retry": 0,
												"retryIntervalInSeconds": 30,
												"secureOutput": false,
												"secureInput": false
											},
											"userProperties": [],
											"typeProperties": {
												"source": {
													"type": "BinarySource",
													"storeSettings": {
														"type": "AzureBlobStorageReadSettings",
														"recursive": true
													},
													"formatSettings": {
														"type": "BinaryReadSettings"
													}
												},
												"sink": {
													"type": "BinarySink",
													"storeSettings": {
														"type": "AzureBlobStorageWriteSettings"
													}
												},
												"enableStaging": false
											},
											"inputs": [
												{
													"referenceName": "inputDataDataset",
													"type": "DatasetReference",
													"parameters": {}
												}
											],
											"outputs": [
												{
													"referenceName": "outdataset_switch",
													"type": "DatasetReference",
													"parameters": {
														"foldername": {
															"value": "@pipeline().parameters.folder",
															"type": "Expression"
														}
													}
												}
											]
										}
									]
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"folder": {
						"type": "string"
					}
				},
				"annotations": [],
				"lastPublishTime": "2025-03-30T18:04:06Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/unpivot_inline_ds_dataflow_pipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "unpivot_inline_ds_dataflow",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "unpivot_inline_ds_dataflow",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/until_activity_pipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Until_activity",
						"type": "Until",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@bool(variables('fileavail'))",
								"type": "Expression"
							},
							"activities": [
								{
									"name": "Get Metadata1",
									"type": "GetMetadata",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataset": {
											"referenceName": "SourceDataset_until",
											"type": "DatasetReference",
											"parameters": {}
										},
										"fieldList": [
											"exists"
										],
										"storeSettings": {
											"type": "AzureBlobStorageReadSettings",
											"recursive": true,
											"enablePartitionDiscovery": false
										},
										"formatSettings": {
											"type": "BinaryReadSettings"
										}
									}
								},
								{
									"name": "If Condition1",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "Get Metadata1",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@bool(activity('Get Metadata1').output.exists)",
											"type": "Expression"
										},
										"ifFalseActivities": [
											{
												"name": "Wait1",
												"type": "Wait",
												"dependsOn": [],
												"userProperties": [],
												"typeProperties": {
													"waitTimeInSeconds": 60
												}
											}
										],
										"ifTrueActivities": [
											{
												"name": "Set variable1",
												"type": "SetVariable",
												"dependsOn": [],
												"policy": {
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"variableName": "fileavail",
													"value": "True"
												}
											}
										]
									}
								}
							],
							"timeout": "0.12:00:00"
						}
					},
					{
						"name": "Copy data1",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "Until_activity",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "BinarySource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true
								},
								"formatSettings": {
									"type": "BinaryReadSettings"
								}
							},
							"sink": {
								"type": "BinarySink",
								"storeSettings": {
									"type": "AzureBlobStorageWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "SourceDataset_until",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "after_until_output",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"variables": {
					"fileavail": {
						"type": "String",
						"defaultValue": "False"
					}
				},
				"annotations": [],
				"lastPublishTime": "2025-03-30T14:55:31Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/trigger_sp_pipeline')]",
			"type": "Microsoft.DataFactory/factories/triggers",
			"apiVersion": "2018-06-01",
			"properties": {
				"annotations": [],
				"runtimeState": "Started",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "sp_pipeline",
							"type": "PipelineReference"
						},
						"parameters": {}
					}
				],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Minute",
						"interval": 20,
						"startTime": "2025-03-31T13:10:00",
						"endTime": "2025-03-31T13:13:00",
						"timeZone": "India Standard Time"
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/aggregation_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "emopdetails_agg_dataflow",
								"type": "DatasetReference"
							},
							"name": "empdetails"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "empcount_out_agg_dataflow",
								"type": "DatasetReference"
							},
							"name": "empaggdata"
						}
					],
					"transformations": [
						{
							"name": "empcount"
						}
					],
					"scriptLines": [
						"parameters{",
						"     filename as string",
						"}",
						"source(output(",
						"          empid as short,",
						"          name as string,",
						"          country as string,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empdetails",
						"empdetails aggregate(groupBy(deptname),",
						"     Employee_count = count(empid)) ~> empcount",
						"empcount sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:[($filename)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> empaggdata"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/alter_row_trans_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "input_ds_window_trans",
								"type": "DatasetReference"
							},
							"name": "sourcedsemp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "alter_row_out_ds",
								"type": "DatasetReference"
							},
							"name": "sinktbloutput"
						}
					],
					"transformations": [
						{
							"name": "alterRows"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          name as string,",
						"          gender as string,",
						"          salary as integer,",
						"          dept as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> sourcedsemp",
						"sourcedsemp alterRow(deleteIf(dept=='Payroll'),",
						"     upsertIf(dept=='HR')) ~> alterRows",
						"alterRows sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as integer,",
						"          name as string,",
						"          gender as string,",
						"          salary as integer,",
						"          dept as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:true,",
						"     upsertable:true,",
						"     keys:['id'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          id,",
						"          name,",
						"          gender,",
						"          salary,",
						"          dept",
						"     )) ~> sinktbloutput"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/cache_sink_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "emp_table_ds",
								"type": "DatasetReference"
							},
							"name": "emptable"
						},
						{
							"dataset": {
								"referenceName": "emp_details_1_ds",
								"type": "DatasetReference"
							},
							"name": "empdetails1"
						},
						{
							"dataset": {
								"referenceName": "country_table_ds",
								"type": "DatasetReference"
							},
							"name": "countrytable"
						}
					],
					"sinks": [
						{
							"name": "cacheMaxEmpID"
						},
						{
							"name": "cacheCountryName"
						},
						{
							"dataset": {
								"referenceName": "emp_table_ds",
								"type": "DatasetReference"
							},
							"name": "emptableinserts"
						}
					],
					"transformations": [
						{
							"name": "generateempid"
						},
						{
							"name": "derivedColumnempid"
						}
					],
					"scriptLines": [
						"source(output(",
						"          maxEmpID as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: 'select max(empid) as maxEmpID from emp_table',",
						"     format: 'query') ~> emptable",
						"source(output(",
						"          name as string,",
						"          gender as string,",
						"          country as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empdetails1",
						"source(output(",
						"          code as string,",
						"          country as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> countrytable",
						"empdetails1 keyGenerate(output(empid as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> generateempid",
						"generateempid derive(empid = cacheMaxEmpID#output().maxEmpID + empid,",
						"          country = cacheCountryName#lookup(country).country) ~> derivedColumnempid",
						"emptable sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: false,",
						"     saveOrder: 0,",
						"     mapColumn(",
						"          maxEmpID",
						"     )) ~> cacheMaxEmpID",
						"countrytable sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     keys:['code'],",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: false,",
						"     saveOrder: 0,",
						"     mapColumn(",
						"          code,",
						"          country",
						"     )) ~> cacheCountryName",
						"derivedColumnempid sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as integer,",
						"          name as string,",
						"          gender as string,",
						"          country as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          name,",
						"          gender,",
						"          country",
						"     )) ~> emptableinserts"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/conditional_split_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "emopdetails_agg_dataflow",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "split_dataflow_ds",
								"type": "DatasetReference"
							},
							"name": "ITemp"
						},
						{
							"dataset": {
								"referenceName": "split_dataflow_ds",
								"type": "DatasetReference"
							},
							"name": "PayrollEmp"
						},
						{
							"dataset": {
								"referenceName": "split_dataflow_ds",
								"type": "DatasetReference"
							},
							"name": "HREmp"
						},
						{
							"dataset": {
								"referenceName": "split_dataflow_ds",
								"type": "DatasetReference"
							},
							"name": "DefaultEmp"
						}
					],
					"transformations": [
						{
							"name": "splitBasedOnDept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as short,",
						"          name as string,",
						"          country as string,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"employee split(equals(deptname, 'IT'),",
						"     equals(deptname,'HR'),",
						"     equals(deptname,'PAYROLL'),",
						"     disjoint: false) ~> splitBasedOnDept@(IT, HR, PAYROLL, Otherdept)",
						"splitBasedOnDept@IT sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptname as string,",
						"          Employee_count as string",
						"     ),",
						"     partitionFileNames:['ITEmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> ITemp",
						"splitBasedOnDept@PAYROLL sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptname as string,",
						"          Employee_count as string",
						"     ),",
						"     partitionFileNames:['PayrollEmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> PayrollEmp",
						"splitBasedOnDept@HR sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptname as string,",
						"          Employee_count as string",
						"     ),",
						"     partitionFileNames:['HREmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> HREmp",
						"splitBasedOnDept@Otherdept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptname as string,",
						"          Employee_count as string",
						"     ),",
						"     partitionFileNames:['OtherEmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> DefaultEmp"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/derived_column_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empdataset_derived_df",
								"type": "DatasetReference"
							},
							"name": "empdetails"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "emp_details_table_ds",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumnCountry"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          deptname as string,",
						"          age as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empdetails",
						"empdetails derive(country = iifNull(country,'No country present'),",
						"          Age_group = iif(age < 25 , 'young', iif((age >= 25 && age < 50), 'adult', 'senior'))) ~> derivedColumnCountry",
						"derivedColumnCountry sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as integer,",
						"          ename as string,",
						"          country as string,",
						"          deptname as string,",
						"          age as integer,",
						"          AGE_GROUP as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     truncate:true,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          id = empid,",
						"          ename = name,",
						"          country,",
						"          deptname,",
						"          age,",
						"          AGE_GROUP = Age_group",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/exists_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empdataset_adls",
								"type": "DatasetReference"
							},
							"name": "employee"
						},
						{
							"dataset": {
								"referenceName": "departmentdataset_adls",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "exists_dataset_sink",
								"type": "DatasetReference"
							},
							"name": "existssink"
						},
						{
							"dataset": {
								"referenceName": "exists_dataset_sink",
								"type": "DatasetReference"
							},
							"name": "notexixtssink"
						}
					],
					"transformations": [
						{
							"name": "deptempexists"
						},
						{
							"name": "deptnoempexists"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"source(output(",
						"          deptid as integer,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> department",
						"department, employee exists(department@deptid == employee@deptid,",
						"     negate:false,",
						"     broadcast: 'auto')~> deptempexists",
						"department, employee exists(department@deptid == employee@deptid,",
						"     negate:true,",
						"     broadcast: 'auto')~> deptnoempexists",
						"deptempexists sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as string,",
						"          name as string,",
						"          sales as string,",
						"          date as string",
						"     ),",
						"     partitionFileNames:['dept_where_emp_exixts.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> existssink",
						"deptnoempexists sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as string,",
						"          name as string,",
						"          sales as string,",
						"          date as string",
						"     ),",
						"     partitionFileNames:['dept_where_no_emp_exixts.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> notexixtssink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/filter_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "emp_dept_dataset",
								"type": "DatasetReference"
							},
							"name": "empdept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "sinkdataset_dataflow",
								"type": "DatasetReference"
							},
							"name": "filteredemp"
						}
					],
					"transformations": [
						{
							"name": "filterdept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          empname as string,",
						"          country as string,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> empdept",
						"empdept filter(equals(deptname,'Payroll')) ~> filterdept",
						"filterdept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as string,",
						"          name as string,",
						"          sales as string,",
						"          date as string",
						"     ),",
						"     partitionFileNames:['Payrollemp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> filteredemp"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/flatten_trans_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "flatten_trans_dataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "flatten_dataflow_out_ds",
								"type": "DatasetReference"
							},
							"name": "flattenoutsink"
						}
					],
					"transformations": [
						{
							"name": "flatten1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          name as string,",
						"          skills as string[]",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'documentPerLine') ~> source1",
						"source1 foldDown(unroll(skills),",
						"     mapColumn(",
						"          id,",
						"          name,",
						"          skills",
						"     ),",
						"     partitionBy('hash', 1),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flatten1",
						"flatten1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Flatten_array_data.json'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          id,",
						"          name,",
						"          skills",
						"     ),",
						"     partitionBy('hash', 1)) ~> flattenoutsink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/group_by_powerquery')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "WranglingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "empdataset_derived_df",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> empdataset_derived_df",
							"dataset": {
								"referenceName": "empdataset_derived_df",
								"type": "DatasetReference"
							}
						}
					],
					"script": "section Section1;\r\nshared empdataset_derived_df = let AdfDoc = AzureStorage.DataLakeContents(\"https://storageadlsdemooin.dfs.core.windows.net/adfdemooinadls/input/emp_for_derived.csv\"),Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]), PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true]),\r\n  #\"Changed column type\" = Table.TransformColumnTypes(PromotedHeaders, {{\"empid\", Int64.Type}, {\"age\", Int64.Type}}) in  #\"Changed column type\";\r\nshared UserQuery = let Source = #\"empdataset_derived_df\",\r\n  #\"Grouped rows\" = Table.Group(Source, {\"deptname\"}, {{\"TotalEmp\", each Table.RowCount(_), Int64.Type}}) in #\"Grouped rows\";\r\n",
					"documentLocale": "en-us"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/join_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empdataset_adls",
								"type": "DatasetReference"
							},
							"name": "employee"
						},
						{
							"dataset": {
								"referenceName": "departmentdataset_adls",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "emp_dept_dataset",
								"type": "DatasetReference"
							},
							"name": "empdept"
						}
					],
					"transformations": [
						{
							"name": "joinempdept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          deptid as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"source(output(",
						"          deptid as string,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> department",
						"employee, department join(employee@deptid == department@deptid,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> joinempdept",
						"joinempdept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as integer,",
						"          empname as string,",
						"          country as string,",
						"          deptname as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empname = name,",
						"          country,",
						"          deptname",
						"     )) ~> empdept"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/lookup_trans_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empDataset_lkp_transformation",
								"type": "DatasetReference"
							},
							"name": "employee"
						},
						{
							"dataset": {
								"referenceName": "deptDataset_lkp_transformation",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "out_lkp_trans_dataset",
								"type": "DatasetReference"
							},
							"name": "empwithdeptname"
						}
					],
					"transformations": [
						{
							"name": "lookupdept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          deptid as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"source(output(",
						"          deptid as string,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> department",
						"employee, department lookup(employee@deptid == department@deptid,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookupdept",
						"lookupdept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as string,",
						"          name as string,",
						"          sales as string,",
						"          date as string",
						"     ),",
						"     partitionFileNames:['Emp_with_dept_name.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> empwithdeptname"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/merge_queries_powerquery')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "WranglingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "empdataset_adls",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> empdataset_adls",
							"dataset": {
								"referenceName": "empdataset_adls",
								"type": "DatasetReference"
							}
						},
						{
							"name": "departmentdataset_adls",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> departmentdataset_adls",
							"dataset": {
								"referenceName": "departmentdataset_adls",
								"type": "DatasetReference"
							}
						}
					],
					"script": "section Section1;\r\nshared empdataset_adls = let AdfDoc = AzureStorage.DataLakeContents(\"https://storageadlsdemooin.dfs.core.windows.net/adfdemooinadls/input/employees.csv\"),Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]), PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true]) in  PromotedHeaders;\r\nshared departmentdataset_adls = let AdfDoc = AzureStorage.DataLakeContents(\"https://storageadlsdemooin.dfs.core.windows.net/adfdemooinadls/input/department.csv\"),Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]), PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true]) in  PromotedHeaders;\r\nshared UserQuery = let Source = #\"empdataset_adls\",\r\n  #\"Merged queries\" = Table.NestedJoin(Source, {\"deptid\"}, departmentdataset_adls, {\"deptid\"}, \"departmentdataset_adls\", JoinKind.Inner),\r\n  #\"Expanded departmentdataset_adls\" = Table.ExpandTableColumn(#\"Merged queries\", \"departmentdataset_adls\", {\"deptname\"}, {\"deptname\"}) in #\"Expanded departmentdataset_adls\";\r\n",
					"documentLocale": "en-us"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/new_branch_work_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empDataset_lkp_transformation",
								"type": "DatasetReference"
							},
							"name": "employee"
						},
						{
							"dataset": {
								"referenceName": "deptDataset_lkp_transformation",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "empcountdataset_sink",
								"type": "DatasetReference"
							},
							"name": "empcountsink"
						},
						{
							"dataset": {
								"referenceName": "joineddataset_sink",
								"type": "DatasetReference"
							},
							"name": "joineddatasink"
						}
					],
					"transformations": [
						{
							"name": "countemp"
						},
						{
							"name": "joinempdept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"source(output(",
						"          deptid as integer,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> department",
						"employee aggregate(groupBy(deptid),",
						"     count_of_emp = count(empid)) ~> countemp",
						"employee, department join(employee@deptid == department@deptid,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> joinempdept",
						"countemp sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptname as string,",
						"          Employee_count as string",
						"     ),",
						"     partitionFileNames:['Emp_count_dept_wise.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> empcountsink",
						"joinempdept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptname as string,",
						"          Employee_count as string",
						"     ),",
						"     partitionFileNames:['Joined_emp_dept.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> joineddatasink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/parse_trans_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_tbl_employee",
								"type": "DatasetReference"
							},
							"name": "emptable"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "out_parse_trans",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "parseskills"
						},
						{
							"name": "parseaddress"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          empname as string,",
						"          skills as string,",
						"          address as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> emptable",
						"emptable parse(Parseskills = skills ? (skill1 as string,",
						"          skill2 as string,",
						"          skill3 as string),",
						"     format: 'delimited',",
						"     columnNamesAsHeader: false,",
						"     columnDelimiter: '|',",
						"     nullValue: '') ~> parseskills",
						"parseskills parse(Parseaddress = address ? (city as string,",
						"          country as string),",
						"     format: 'json',",
						"     documentForm: 'singleDocument') ~> parseaddress",
						"parseaddress sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Parse_trans_out.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empname,",
						"          skill1 = Parseskills.skill1,",
						"          skill2 = Parseskills.skill2,",
						"          skill3 = Parseskills.skill3,",
						"          city = Parseaddress.city,",
						"          country = Parseaddress.country",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		}
	]
}