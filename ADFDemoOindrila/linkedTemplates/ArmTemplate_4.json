{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "ADFDemoOindrila"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/conditional_split_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "emopdetails_agg_dataflow",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "split_dataflow_ds",
								"type": "DatasetReference"
							},
							"name": "ITemp"
						},
						{
							"dataset": {
								"referenceName": "split_dataflow_ds",
								"type": "DatasetReference"
							},
							"name": "PayrollEmp"
						},
						{
							"dataset": {
								"referenceName": "split_dataflow_ds",
								"type": "DatasetReference"
							},
							"name": "HREmp"
						},
						{
							"dataset": {
								"referenceName": "split_dataflow_ds",
								"type": "DatasetReference"
							},
							"name": "DefaultEmp"
						}
					],
					"transformations": [
						{
							"name": "splitBasedOnDept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as short,",
						"          name as string,",
						"          country as string,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"employee split(equals(deptname, 'IT'),",
						"     equals(deptname,'HR'),",
						"     equals(deptname,'PAYROLL'),",
						"     disjoint: false) ~> splitBasedOnDept@(IT, HR, PAYROLL, Otherdept)",
						"splitBasedOnDept@IT sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptname as string,",
						"          Employee_count as string",
						"     ),",
						"     partitionFileNames:['ITEmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> ITemp",
						"splitBasedOnDept@PAYROLL sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptname as string,",
						"          Employee_count as string",
						"     ),",
						"     partitionFileNames:['PayrollEmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> PayrollEmp",
						"splitBasedOnDept@HR sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptname as string,",
						"          Employee_count as string",
						"     ),",
						"     partitionFileNames:['HREmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> HREmp",
						"splitBasedOnDept@Otherdept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptname as string,",
						"          Employee_count as string",
						"     ),",
						"     partitionFileNames:['OtherEmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> DefaultEmp"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/derived_column_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empdataset_derived_df",
								"type": "DatasetReference"
							},
							"name": "empdetails"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "emp_details_table_ds",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumnCountry"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          deptname as string,",
						"          age as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empdetails",
						"empdetails derive(country = iifNull(country,'No country present'),",
						"          Age_group = iif(age < 25 , 'young', iif((age >= 25 && age < 50), 'adult', 'senior'))) ~> derivedColumnCountry",
						"derivedColumnCountry sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as integer,",
						"          ename as string,",
						"          country as string,",
						"          deptname as string,",
						"          age as integer,",
						"          AGE_GROUP as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     truncate:true,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          id = empid,",
						"          ename = name,",
						"          country,",
						"          deptname,",
						"          age,",
						"          AGE_GROUP = Age_group",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/exists_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empdataset_adls",
								"type": "DatasetReference"
							},
							"name": "employee"
						},
						{
							"dataset": {
								"referenceName": "departmentdataset_adls",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "exists_dataset_sink",
								"type": "DatasetReference"
							},
							"name": "existssink"
						},
						{
							"dataset": {
								"referenceName": "exists_dataset_sink",
								"type": "DatasetReference"
							},
							"name": "notexixtssink"
						}
					],
					"transformations": [
						{
							"name": "deptempexists"
						},
						{
							"name": "deptnoempexists"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"source(output(",
						"          deptid as integer,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> department",
						"department, employee exists(department@deptid == employee@deptid,",
						"     negate:false,",
						"     broadcast: 'auto')~> deptempexists",
						"department, employee exists(department@deptid == employee@deptid,",
						"     negate:true,",
						"     broadcast: 'auto')~> deptnoempexists",
						"deptempexists sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as string,",
						"          name as string,",
						"          sales as string,",
						"          date as string",
						"     ),",
						"     partitionFileNames:['dept_where_emp_exixts.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> existssink",
						"deptnoempexists sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as string,",
						"          name as string,",
						"          sales as string,",
						"          date as string",
						"     ),",
						"     partitionFileNames:['dept_where_no_emp_exixts.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> notexixtssink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/filter_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "emp_dept_dataset",
								"type": "DatasetReference"
							},
							"name": "empdept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "sinkdataset_dataflow",
								"type": "DatasetReference"
							},
							"name": "filteredemp"
						}
					],
					"transformations": [
						{
							"name": "filterdept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          empname as string,",
						"          country as string,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> empdept",
						"empdept filter(equals(deptname,'Payroll')) ~> filterdept",
						"filterdept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as string,",
						"          name as string,",
						"          sales as string,",
						"          date as string",
						"     ),",
						"     partitionFileNames:['Payrollemp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> filteredemp"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/flatten_trans_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "flatten_trans_dataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "flatten_dataflow_out_ds",
								"type": "DatasetReference"
							},
							"name": "flattenoutsink"
						}
					],
					"transformations": [
						{
							"name": "flatten1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          name as string,",
						"          skills as string[]",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'documentPerLine') ~> source1",
						"source1 foldDown(unroll(skills),",
						"     mapColumn(",
						"          id,",
						"          name,",
						"          skills",
						"     ),",
						"     partitionBy('hash', 1),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flatten1",
						"flatten1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Flatten_array_data.json'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          id,",
						"          name,",
						"          skills",
						"     ),",
						"     partitionBy('hash', 1)) ~> flattenoutsink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/group_by_powerquery')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "WranglingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "empdataset_derived_df",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> empdataset_derived_df",
							"dataset": {
								"referenceName": "empdataset_derived_df",
								"type": "DatasetReference"
							}
						}
					],
					"script": "section Section1;\r\nshared empdataset_derived_df = let AdfDoc = AzureStorage.DataLakeContents(\"https://storageadlsdemooin.dfs.core.windows.net/adfdemooinadls/input/emp_for_derived.csv\"),Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]), PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true]),\r\n  #\"Changed column type\" = Table.TransformColumnTypes(PromotedHeaders, {{\"empid\", Int64.Type}, {\"age\", Int64.Type}}) in  #\"Changed column type\";\r\nshared UserQuery = let Source = #\"empdataset_derived_df\",\r\n  #\"Grouped rows\" = Table.Group(Source, {\"deptname\"}, {{\"TotalEmp\", each Table.RowCount(_), Int64.Type}}) in #\"Grouped rows\";\r\n",
					"documentLocale": "en-us"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/join_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empdataset_adls",
								"type": "DatasetReference"
							},
							"name": "employee"
						},
						{
							"dataset": {
								"referenceName": "departmentdataset_adls",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "emp_dept_dataset",
								"type": "DatasetReference"
							},
							"name": "empdept"
						}
					],
					"transformations": [
						{
							"name": "joinempdept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          deptid as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"source(output(",
						"          deptid as string,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> department",
						"employee, department join(employee@deptid == department@deptid,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> joinempdept",
						"joinempdept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as integer,",
						"          empname as string,",
						"          country as string,",
						"          deptname as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empname = name,",
						"          country,",
						"          deptname",
						"     )) ~> empdept"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/lookup_trans_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empDataset_lkp_transformation",
								"type": "DatasetReference"
							},
							"name": "employee"
						},
						{
							"dataset": {
								"referenceName": "deptDataset_lkp_transformation",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "out_lkp_trans_dataset",
								"type": "DatasetReference"
							},
							"name": "empwithdeptname"
						}
					],
					"transformations": [
						{
							"name": "lookupdept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          deptid as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"source(output(",
						"          deptid as string,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> department",
						"employee, department lookup(employee@deptid == department@deptid,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookupdept",
						"lookupdept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as string,",
						"          name as string,",
						"          sales as string,",
						"          date as string",
						"     ),",
						"     partitionFileNames:['Emp_with_dept_name.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> empwithdeptname"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/merge_queries_powerquery')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "WranglingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "empdataset_adls",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> empdataset_adls",
							"dataset": {
								"referenceName": "empdataset_adls",
								"type": "DatasetReference"
							}
						},
						{
							"name": "departmentdataset_adls",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> departmentdataset_adls",
							"dataset": {
								"referenceName": "departmentdataset_adls",
								"type": "DatasetReference"
							}
						}
					],
					"script": "section Section1;\r\nshared empdataset_adls = let AdfDoc = AzureStorage.DataLakeContents(\"https://storageadlsdemooin.dfs.core.windows.net/adfdemooinadls/input/employees.csv\"),Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]), PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true]) in  PromotedHeaders;\r\nshared departmentdataset_adls = let AdfDoc = AzureStorage.DataLakeContents(\"https://storageadlsdemooin.dfs.core.windows.net/adfdemooinadls/input/department.csv\"),Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]), PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true]) in  PromotedHeaders;\r\nshared UserQuery = let Source = #\"empdataset_adls\",\r\n  #\"Merged queries\" = Table.NestedJoin(Source, {\"deptid\"}, departmentdataset_adls, {\"deptid\"}, \"departmentdataset_adls\", JoinKind.Inner),\r\n  #\"Expanded departmentdataset_adls\" = Table.ExpandTableColumn(#\"Merged queries\", \"departmentdataset_adls\", {\"deptname\"}, {\"deptname\"}) in #\"Expanded departmentdataset_adls\";\r\n",
					"documentLocale": "en-us"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/new_branch_work_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empDataset_lkp_transformation",
								"type": "DatasetReference"
							},
							"name": "employee"
						},
						{
							"dataset": {
								"referenceName": "deptDataset_lkp_transformation",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "empcountdataset_sink",
								"type": "DatasetReference"
							},
							"name": "empcountsink"
						},
						{
							"dataset": {
								"referenceName": "joineddataset_sink",
								"type": "DatasetReference"
							},
							"name": "joineddatasink"
						}
					],
					"transformations": [
						{
							"name": "countemp"
						},
						{
							"name": "joinempdept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"source(output(",
						"          deptid as integer,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> department",
						"employee aggregate(groupBy(deptid),",
						"     count_of_emp = count(empid)) ~> countemp",
						"employee, department join(employee@deptid == department@deptid,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> joinempdept",
						"countemp sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptname as string,",
						"          Employee_count as string",
						"     ),",
						"     partitionFileNames:['Emp_count_dept_wise.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> empcountsink",
						"joinempdept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptname as string,",
						"          Employee_count as string",
						"     ),",
						"     partitionFileNames:['Joined_emp_dept.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> joineddatasink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pivot_trans_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "emp_source_dataset_for_pivot",
								"type": "DatasetReference"
							},
							"name": "empsource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "pivot_out_sink",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "pivotgender"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          name as string,",
						"          gender as string,",
						"          country as string,",
						"          department as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> empsource",
						"empsource pivot(groupBy(department),",
						"     pivotBy(gender),",
						"     {} = count(id),",
						"     columnNaming: '$N$V',",
						"     lateral: true) ~> pivotgender",
						"pivotgender sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          count_of_emp as string",
						"     ),",
						"     partitionFileNames:['pivotted_output.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/rank_trans_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "input_ds_window_trans",
								"type": "DatasetReference"
							},
							"name": "empdata"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "out_ds_for_rank",
								"type": "DatasetReference"
							},
							"name": "rankedsink"
						}
					],
					"transformations": [
						{
							"name": "rankOnsalary"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          name as string,",
						"          gender as string,",
						"          salary as integer,",
						"          dept as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empdata",
						"empdata rank(desc(salary, true),",
						"     output(salary_ranking as long)) ~> rankOnsalary",
						"rankOnsalary sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Out_ranked_sal.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          id,",
						"          name,",
						"          gender,",
						"          salary,",
						"          dept,",
						"          salary_ranking",
						"     ),",
						"     partitionBy('hash', 1)) ~> rankedsink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/select_trans_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empDataset_lkp_transformation",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "emp_selected_dataset",
								"type": "DatasetReference"
							},
							"name": "selectedcolssink"
						}
					],
					"transformations": [
						{
							"name": "selectcolumns"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"employee select(mapColumn(",
						"          employee_id = empid,",
						"          country,",
						"          emp_name = name",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectcolumns",
						"selectcolumns sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     format: 'parquet',",
						"     partitionFileNames:['selected_emp_data.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          employee_id,",
						"          country,",
						"          emp_name",
						"     ),",
						"     partitionBy('hash', 1)) ~> selectedcolssink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/sort_trans_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empDataset_lkp_transformation",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "emp_sort_trans_dataset",
								"type": "DatasetReference"
							},
							"name": "emporderedsink"
						}
					],
					"transformations": [
						{
							"name": "sortdeptidcntry"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"employee sort(asc(deptid, true),",
						"     desc(country, true)) ~> sortdeptidcntry",
						"sortdeptidcntry sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          deptid as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          name,",
						"          country,",
						"          deptid",
						"     )) ~> emporderedsink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/surr_key_trans_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "input_dataset_sugg_key",
								"type": "DatasetReference"
							},
							"name": "source"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "surr_ds_output",
								"type": "DatasetReference"
							},
							"name": "surrkeysink"
						}
					],
					"transformations": [
						{
							"name": "surrogateKeygenerate"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Country as string,",
						"          Emp as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source",
						"source keyGenerate(output(empid as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKeygenerate",
						"surrogateKeygenerate sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as string,",
						"          name as string,",
						"          sales as string,",
						"          date as string",
						"     ),",
						"     partitionFileNames:['surr_key_out.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> surrkeysink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/union_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "union_dataset_1",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "union_dataset_2",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "union_out_dataset",
								"type": "DatasetReference"
							},
							"name": "targetemp"
						}
					],
					"transformations": [
						{
							"name": "union2source"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          ename as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> source1",
						"source(output(",
						"          id as integer,",
						"          ename as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> source2",
						"source1, source2 union(byName: true)~> union2source",
						"union2source sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as integer,",
						"          ename as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     truncate:true,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          id,",
						"          ename",
						"     )) ~> targetemp"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/unpivot_trans_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "source_ds_unpivot",
								"type": "DatasetReference"
							},
							"name": "sourceforunpivot"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "unpivot_out_dataset",
								"type": "DatasetReference"
							},
							"name": "unpivotoutsink"
						}
					],
					"transformations": [
						{
							"name": "unpivot"
						}
					],
					"scriptLines": [
						"source(output(",
						"          PO as integer,",
						"          Vendor as string,",
						"          Apple as integer,",
						"          Mango as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> sourceforunpivot",
						"sourceforunpivot unpivot(output(",
						"          Fruits as string,",
						"          Amount as integer",
						"     ),",
						"     ungroupBy(Vendor,",
						"          PO),",
						"     lateral: true,",
						"     ignoreNullPivots: false) ~> unpivot",
						"unpivot sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          count_of_emp as string",
						"     ),",
						"     partitionFileNames:['purcchase_order_unpivot.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> unpivotoutsink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/windows_trans_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "input_ds_window_trans",
								"type": "DatasetReference"
							},
							"name": "sourceforranking"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "window_trans_out_ds",
								"type": "DatasetReference"
							},
							"name": "windowssink"
						}
					],
					"transformations": [
						{
							"name": "windowtransbydept"
						}
					],
					"scriptLines": [
						"parameters{",
						"     Filename as string",
						"}",
						"source(output(",
						"          id as integer,",
						"          name as string,",
						"          gender as string,",
						"          salary as integer,",
						"          dept as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> sourceforranking",
						"sourceforranking window(over(dept),",
						"     desc(salary, true),",
						"     dense_rank = denseRank(),",
						"          rank = rank(),",
						"          row_num = rowNumber(),",
						"          cum_sum = cumeDist(),",
						"          avg_sal = avg(salary)) ~> windowtransbydept",
						"windowtransbydept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          count_of_emp as string",
						"     ),",
						"     partitionFileNames:[($Filename)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> windowssink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Alter_Row_trans_Dataflow_pipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Alter_Row_trans_Dataflow",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "alter_row_trans_dataflow",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"sourcedsemp": {},
									"sinktbloutput": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2025-04-02T12:36:12Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Cache_Sink_Dataflow_pipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Cache_Sink_Dataflow",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "cache_sink_dataflow",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"emptable": {},
									"empdetails1": {},
									"countrytable": {},
									"cacheMaxEmpID": {},
									"cacheCountryName": {},
									"emptableinserts": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": []
		}
	]
}